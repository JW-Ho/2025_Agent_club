{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0.Assignments\n",
        "\n",
        "ğŸ‘¾ é€™å€‹é™½æ˜¥çš„èŠå¤©æ©Ÿå™¨äººéœ€è¦è¢«å„ªåŒ–ï¼<br>\n",
        "è‹¥æ˜¯ä¸€å€‹å°è©±ä¸²ä¸é–“æ–·åœ°æŒçºŒé€²è¡Œï¼Œé€é€²å»çš„è¨Šæ¯é‡æœƒå¾ˆå¤šï¼Œtokensæ•¸é‡ä¹Ÿæœƒè·Ÿè‘—å¢åŠ ï¼Œæœƒéœ€è¦èŠ±æ¯”è¼ƒå¤šè²»ç”¨(ğŸ’¸ğŸ’¸ğŸ’¸)ï¼Œä¹Ÿå¯èƒ½ä½¿æ¨¡å‹çš„å›æ‡‰é›œè¨Šæ¯”è¼ƒå¤šè€Œå›æ‡‰å—åˆ°å¹²æ“¾ï¼Œæ‰€ä»¥æˆ‘å€‘å¯ä»¥å„ªåŒ–çŸ­æœŸè¨˜æ†¶ã€‚<br>\n",
        "å¦å¤–ï¼Œæˆ‘å€‘å¸Œæœ›å„ªåŒ–ä½¿ç”¨è€…é«”é©—ï¼Œæˆ‘å€‘å¯ä»¥æ ¹æ“šèŠå¤©çš„å…§å®¹æ•´ç†å‡ºä½¿ç”¨è€…çš„å±¬æ€§ï¼Œä¸¦åœ¨æ¯ä¸€æ¬¡è·Ÿä½¿ç”¨è€…èŠå¤©æ™‚ï¼Œéƒ½èƒ½æ ¹æ“šé€™å€‹ä½¿ç”¨è€…çš„ç‹€æ³çµ¦äºˆå®¢è£½åŒ–çš„å›æ‡‰ï¼Œå› æ­¤æˆ‘å€‘è¦åŠ å…¥é•·æœŸè¨˜æ†¶çš„åŠŸèƒ½ï¼\n",
        "\n",
        "<br>\n",
        "\n",
        "### 1. çŸ­æœŸè¨˜æ†¶å„ªåŒ–\n",
        "\n",
        "(1) ğŸ”° [åŸºæœ¬ç‰ˆ] åœ¨çŸ­æœŸè¨˜æ†¶ä¸­ï¼Œå°‡chatbot nodeé€å…¥llmçš„è¨Šæ¯ä¸­åŠ å…¥trimçš„å„ªåŒ–æ©Ÿåˆ¶ (ä¾æ“šé©ç•¶çš„tokensæ•¸é‡æ±ºå®š)\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "### 2. åŠ å…¥é•·æœŸè¨˜æ†¶\n",
        "\n",
        "åŠ å…¥é•·æœŸè¨˜æ†¶ï¼Œè®“èŠå¤©æ©Ÿå™¨äººèƒ½å¤ è¨˜ä½ä½¿ç”¨è€…çš„è³‡è¨Šï¼ˆåå­—ã€åå¥½èªè¨€ã€èˆˆè¶£ï¼‰ï¼Œåœ¨ä¸‹ä¸€æ¬¡å°è©±ä¹Ÿèƒ½é‡å°åŒå€‹ä½¿ç”¨è€…çš„è³‡è¨Šï¼Œçµ¦äºˆå€‹äººåŒ–çš„å›ç­”ã€‚\n",
        "\n",
        "(1) ğŸ”° [åŸºæœ¬ç‰ˆ]\n",
        "- chatbot node: åœ¨chatbot nodeä¸­ï¼Œå°‡è©²ä½¿ç”¨è€…çš„è³‡è¨Šå–å‡ºï¼Œè®“å…¥promptä¸­è®“llmä¾æ“šä½¿ç”¨è€…çš„è³‡è¨Šçµ¦äºˆå€‹äººåŒ–çš„å›ç­”\n",
        "\n",
        "- write_memory node: åœ¨æ¯ä¸€æ¬¡ç”Ÿæˆå›ç­”å¾Œï¼Œå°‡ä½¿ç”¨è€…çš„è³‡è¨Šæ•´ç†æˆä¸€æ®µå°ä½¿ç”¨è€…çš„æè¿°(ä½¿ç”¨llmï¼Œçµ¦äºˆsystem promptåšæŒ‡å¼•ï¼Œè‡ªè¡Œè¨­è¨ˆå¦‚ä½•æ•´ç†ã€éœ€è¦æ•´ç†å“ªäº›è³‡è¨Š)ï¼Œå°‡æ•´ç†å®Œçš„è³‡è¨Šæ•´ç†åˆ°store (å¯è·¨threadså­˜å–çš„åœ°æ–¹)ã€‚\n",
        "\n",
        "- config: configå¾åŸæœ¬çš„çŸ­æœŸè¨˜æ†¶åªæœ‰thread_id, ä¹Ÿè¦åŠ å…¥user_id\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1H4Y0WplOi6R4Eo06Ac2JA_9TbZa2YaRD\" width=\"100\"/>\n",
        "\n",
        "\n",
        "(2) ğŸ‘¨â€ğŸ“ [é€²éšç‰ˆ]\n",
        "- chatbot node: å¯ä»¥æ±ºå®šä½¿ç”¨è€…çš„å•é¡Œæ˜¯å¦éœ€è¦å¾é•·æœŸè¨˜æ†¶ä¸­å–å¾—è³‡è¨Šï¼Œä»¥åŠéœ€è¦å–å¾—ä»€éº¼è³‡è¨Š\n",
        "- write_memory node: å¯ä»¥æ•´ç†æˆç‰¹å®šæ ¼å¼ (ä¾‹å¦‚ï¼šä½¿ç”¨with_structured_outputï¼Œç›¸é—œæ¦‚å¿µå¯ä»¥å»¶ä¼¸åˆ°R3 tool callingå…§å®¹)ã€‚ä¾‹å¦‚ï¼š\n",
        "```\n",
        "user_profile = {\n",
        "  \"first_name\": \"XXXX\",\n",
        "  \"last_name\": \"OOO\",\n",
        "  \"preferred_lang\": [\"en\", \"zh-tw\"]\n",
        "}\n",
        "```\n",
        "- ä¹Ÿå¯ä»¥è‡ªè¡Œå°‡graphçµæ§‹èª¿æ•´è‡ªå·±å–œæ­¡çš„(å¢åˆªä¸åŒnode, conditional router, ...)\n",
        "<br>\n",
        "å‚™è¨»ï¼šåŸºæœ¬ç‰ˆæ˜¯éœ€è¦å¤§å®¶å®Œæˆçš„ï¼Œé€²éšç‰ˆå¯ä»¥è‡ªè¡Œæ±ºå®šæ˜¯å¦æŒ‘æˆ°ï¼ŒEnjoy the ride! ğŸ˜"
      ],
      "metadata": {
        "id": "YzuZTjoZkt7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.çŸ­æœŸè¨˜æ†¶"
      ],
      "metadata": {
        "id": "Zprt5eyzemnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (1) åŸºæœ¬ç‰ˆ\n",
        "ğŸ”° [åŸºæœ¬ç‰ˆ] åœ¨çŸ­æœŸè¨˜æ†¶ä¸­ï¼Œå°‡chatbot nodeé€å…¥llmçš„è¨Šæ¯ä¸­åŠ å…¥trimçš„å„ªåŒ–æ©Ÿåˆ¶ (ä¾æ“šé©ç•¶çš„tokensæ•¸é‡æ±ºå®š)\n",
        "\n",
        "note: å¯ä»¥é‚Šåšé‚Šçœ‹ä¸€ä¸‹trimè¨­å®šçš„æ•ˆæœä»¥åŠå…§éƒ¨é‹ä½œçš„æ©Ÿåˆ¶"
      ],
      "metadata": {
        "id": "PZHRs_NSsfnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "!pip install -U langgraph langchain_openai==0.3.15 langchain transformers bitsandbytes langchain-huggingface\n"
      ],
      "metadata": {
        "id": "m8Ahe-dgr3Qa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "\n",
        "# æœƒéœ€è¦ä¸€é»æ™‚é–“\n",
        "# ä½¿ç”¨ 4-bit é‡åŒ–æ¨¡å‹\n",
        "model_id = \"MediaTek-Research/Breeze-7B-Instruct-v1_0\"\n",
        "\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    llm_int8_threshold=6.0,\n",
        ")\n",
        "\n",
        "# è¼‰å…¥ tokenizer èˆ‡ 4-bit æ¨¡å‹\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quant_config,\n",
        "    trust_remote_code=True\n",
        ")"
      ],
      "metadata": {
        "id": "Ep_VhJl4yKmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\n",
        "    task=\"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    do_sample=True,\n",
        "    temperature=0.4,\n",
        "    return_full_text=False # åƒ…è¿”å›ç”Ÿæˆçš„å›æ‡‰å…§å®¹\n",
        ")\n",
        "\n",
        "# åŒ…è£æˆ LangChain çš„ llm ç‰©ä»¶\n",
        "llm = HuggingFacePipeline(pipeline=generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beAp0_a0yNsP",
        "outputId": "e644edfc-0468-4beb-ec01-26a30323b5b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import convert_to_openai_messages, HumanMessage, AIMessage\n",
        "from langchain_core.runnables.config import RunnableConfig\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_core.messages.utils import trim_messages\n",
        "from langchain_core.messages.utils import count_tokens_approximately\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "  messages: Annotated[list, add_messages]\n",
        "\n",
        "def chatbot(state: State, config: RunnableConfig):\n",
        "  # ğŸ’»code below:\n",
        "  # hint: you can use langchain_core trim_messages function to trim your trim_messages, and count_tokens_approximately to count tokens\n",
        "  \"\"\"\n",
        "  ä¸»è¦è™•ç†chatbotå›æ‡‰çš„é‚è¼¯\n",
        "  é€™è£¡åƒ…å–®ç´”å°‡ä½¿ç”¨è€…çš„å°è©±ç´€éŒ„(å‚³å…¥çš„stateä¸­çš„messages)ï¼Œé€å…¥æ¨¡å‹ç”¢ç”Ÿå›æ‡‰\n",
        "  \"\"\"\n",
        "\n",
        "   # Convert LangChain messages into OpenAI message dicts.\n",
        "  system_prompt = \"ä½ æ˜¯å€‹åªèƒ½ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”çš„åŠ©ç†ï¼Œä¸”ä½ åªéœ€è¦é‡å°å•é¡Œ'ç°¡ç­”'ï¼Œåƒå€‹äººåœ¨å°è©±\"\n",
        "  max_prompt_tokens = 512\n",
        "  trimmed_messages = trim_messages(\n",
        "      messages=state[\"messages\"],\n",
        "      max_tokens=max_prompt_tokens,\n",
        "      token_counter=count_tokens_approximately\n",
        "  )\n",
        "  messages = convert_to_openai_messages(trimmed_messages)\n",
        "  mes = [{\"role\": \"system\", \"content\": system_prompt}] + messages\n",
        "  prompt = tokenizer.apply_chat_template(\n",
        "      mes,\n",
        "      tokenize=False,\n",
        "      add_generation_prompt=True\n",
        "  )\n",
        "\n",
        "\n",
        "  response = llm.invoke(prompt)\n",
        "  return {\"messages\": [AIMessage(content=response)]}\n",
        "\n",
        "\n",
        "# å»ºç«‹graph\n",
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"chatbot\", chatbot) # åœ¨graphè£¡é¢åŠ å…¥chatbotçš„node\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)\n",
        "\n",
        "# åŠ å…¥çŸ­æœŸè¨˜æ†¶\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "bwyMby4dggqz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# çœ‹ä¸€ä¸‹graph\n",
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "Tfjeu3c4uhzz",
        "outputId": "cf1ff8c9-f35f-44af-c783-44425d863378"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str, config: dict):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}, config):\n",
        "      if \"chatbot\" in event:\n",
        "        for value in event.values():\n",
        "          print(\"Assistant:\", value[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "2Ld1Zg3ersQC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# è¨­å®šå°è©±config (ç¬¬ä¸€æ¬¡å°è©±)\n",
        "config = {\"configurable\": {\"thread_id\": \"conversation_1\"}} # thread_id: å°è©±id"
      ],
      "metadata": {
        "id": "Jn6-NIHc0jSG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# é–‹å§‹å°è©± (å¯ä»¥è¼¸å…¥quit, exit, qï¼Œä¸‰é¸ä¸€åœæ­¢å°è©±)\n",
        "while True:\n",
        "  try:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "      print(\"Goodbye!\")\n",
        "      break\n",
        "    stream_graph_updates(user_input, config)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    break"
      ],
      "metadata": {
        "id": "wp-MDjLF0ntY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dacc657-0ab6-4fc5-cf7d-f68cdaddfbb4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: æˆ‘å–œæ­¡å¥èº«\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/nn/modules.py:463: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant: å¥èº«æ˜¯ä¸€ç¨®å¥åº·çš„ç”Ÿæ´»æ–¹å¼ï¼Œå¯ä»¥å¢å¼·èº«é«”ç´ è³ªã€æé«˜å…ç–«åŠ›ã€æ”¹å–„å¿ƒæƒ…ï¼Œä»¥åŠä¿æŒé«”æ…‹ã€‚æ¯å¤©èŠ±ä¸€äº›æ™‚é–“å¥èº«ï¼Œå¯ä»¥æœ‰æ•ˆåœ°é é˜²ç–¾ç—…ï¼Œä¿æŒèº«å¿ƒå¹³è¡¡ã€‚\n",
            "User: æˆ‘å«\n",
            "Assistant: ä½ å¥½ï¼Œå¾ˆé«˜å…´èƒ½ä¸ä½ äº¤æµã€‚è¯·é—®æœ‰ä»€ä¹ˆé—®é¢˜æˆ‘å¯ä»¥å¸®åŠ©ä½ è§£å†³ï¼Ÿ\n",
            "User: æˆ‘å«jame\n",
            "Assistant: ä½ å¥½ï¼ŒJameã€‚è¯·é—®ä½ æœ‰ä»€ä¹ˆé—®é¢˜éœ€è¦æˆ‘çš„å¸®åŠ©å—ï¼Ÿ\n",
            "User: è«‹æˆ‘çš„çš„èˆˆè¶£æ˜¯ä»€éº¼ï¼Ÿ\n",
            "Assistant: ä½ å¥½ï¼ŒJameã€‚ä½ ä¸ªäººçš„å…´è¶£å–å†³äºä½ çš„æ€§æ ¼ã€ç»éªŒå’Œå…´è¶£çˆ±å¥½ã€‚æ ¹æ®æˆ‘çš„ç†è§£ï¼Œä½ å–œæ¬¢å¥èº«ï¼Œè¿™å¯èƒ½è¡¨æ˜ä½ å–œæ¬¢è¿åŠ¨ã€å¥èº«å’Œä¿æŒå¥åº·ã€‚ä½ å¯èƒ½è¿˜æœ‰å…¶ä»–å…´è¶£ï¼Œä¾‹å¦‚ï¼š\n",
            "\n",
            "1. è¿åŠ¨ï¼šè¶³çƒã€ç±ƒçƒã€æ¸¸æ³³ç­‰ã€‚\n",
            "2. è‰ºæœ¯ï¼šç¹ªç•«ã€ä¹¦æ³•ã€éŸ³ä¹ç­‰ã€‚\n",
            "3. ç§‘å­¦ï¼šç‰©ç†ã€åŒ–å­¦ã€å¤©æ–‡ç­‰ã€‚\n",
            "4. ç¤¾åŒºæœå‹™ï¼šå¿—æ„¿è€…ã€å…¬ç›Šæ´»åŠ¨ç­‰ã€‚\n",
            "\n",
            "è¯·å‘Šè¯‰æˆ‘ï¼Œä½ è¿˜æœ‰ä»€ä¹ˆå…´è¶£ï¼Œæˆ‘ä¼šæ ¹æ®ä½ çš„å…´è¶£ç»™ä½ æ¨èä¸€äº›ç›¸å…³èµ„è®¯æˆ–æ´»åŠ¨ã€‚\n",
            "User: q\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "JFqg436etzLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.é•·æœŸè¨˜æ†¶"
      ],
      "metadata": {
        "id": "2O2TZ8VqBpuA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (1) åŸºæœ¬ç‰ˆ\n",
        "ğŸ”° [åŸºæœ¬ç‰ˆ]\n",
        "- chatbot node: åœ¨chatbot nodeä¸­ï¼Œå°‡è©²ä½¿ç”¨è€…çš„è³‡è¨Šå–å‡ºï¼Œè®“å…¥promptä¸­è®“llmä¾æ“šä½¿ç”¨è€…çš„è³‡è¨Šçµ¦äºˆå€‹äººåŒ–çš„å›ç­”\n",
        "\n",
        "- write_memory node: åœ¨æ¯ä¸€æ¬¡ç”Ÿæˆå›ç­”å¾Œï¼Œå°‡ä½¿ç”¨è€…çš„è³‡è¨Šæ•´ç†æˆä¸€æ®µå°ä½¿ç”¨è€…çš„æè¿°(ä½¿ç”¨llmï¼Œçµ¦äºˆsystem promptåšæŒ‡å¼•ï¼Œè‡ªè¡Œè¨­è¨ˆå¦‚ä½•æ•´ç†ã€éœ€è¦æ•´ç†å“ªäº›è³‡è¨Š)ï¼Œå°‡æ•´ç†å®Œçš„è³‡è¨Šæ•´ç†åˆ°store (å¯è·¨threadså­˜å–çš„åœ°æ–¹)ã€‚\n",
        "\n",
        "- config: configå¾åŸæœ¬çš„çŸ­æœŸè¨˜æ†¶åªæœ‰thread_id, ä¹Ÿè¦åŠ å…¥user_id\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1H4Y0WplOi6R4Eo06Ac2JA_9TbZa2YaRD\" width=\"100\"/>"
      ],
      "metadata": {
        "id": "zZSFFrWiuE3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "!pip install langchain_core"
      ],
      "metadata": {
        "id": "VPEkk6s1uZEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.checkpoint.memory import MemorySaver # within-thread memory\n",
        "from langgraph.store.memory import InMemoryStore # cross-thread store\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "  messages: Annotated[list, add_messages]\n",
        "\n",
        "def chatbot(__________):\n",
        "  # ğŸ’»code here:\n",
        "  # TODO:\n",
        "  # ä¾æ“šuser_idå–å¾—é•·æœŸè¨˜æ†¶\n",
        "  # å°‡é•·æœŸè¨˜æ†¶ä¹Ÿæ”¾é€²system promptä¸­ï¼Œè®“llmå¯ä»¥å€‹äººåŒ–å›è¦†\n",
        "\n",
        "\n",
        "  return {\"messages\": [AIMessage(content=response)]}\n",
        "\n",
        "\n",
        "def write_memory(________):\n",
        "  # ğŸ’»code here:\n",
        "  # TODO:\n",
        "  # å°‡ä½¿ç”¨è€…çš„å°è©±æ•´ç†æˆè¦å„²å­˜æˆé•·æœŸè¨˜æ†¶çš„è³‡è¨Šï¼Œä¸¦å­˜å…¥é•·æœŸè¨˜æ†¶\n",
        "\n",
        "# Define the graph\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(\"chatbot\", chatbot)\n",
        "builder.add_node(\"write_memory\", write_memory)\n",
        "builder.add_edge(START, \"chatbot\")\n",
        "builder.add_edge(\"chatbot\", \"write_memory\")\n",
        "builder.add_edge(\"write_memory\", END)\n",
        "\n",
        "\n",
        "# Compile the graph with the checkpointer fir and store\n",
        "\n",
        "# ğŸ’»Code Here\n",
        "# è¨˜å¾—æ”¾å…¥çŸ­æœŸè¨˜æ†¶ï¼Œé•·æœŸè¨˜æ†¶çš„store\n",
        "graph = builder.compile(checkpointer=______, store=________)\n"
      ],
      "metadata": {
        "id": "5czQ-VSKBICQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View\n",
        "from IPython.display import Image, display\n",
        "try:\n",
        "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  pass"
      ],
      "metadata": {
        "id": "KPPiEQpvHKl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str, config: dict):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}, config):\n",
        "        if \"chatbot\" in event:\n",
        "          for value in event.values():\n",
        "              print(\"Assistant:\", value[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "zjdk4Y1tvXyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ä½¿ç”¨è€…Açš„ç¬¬ä¸€æ¬¡å°è©±\n",
        "config = {\"configurable\": {\"thread_id\": \"conversation_1\", \"user_id\": \"user_a\"}}"
      ],
      "metadata": {
        "id": "GMyA_OCNBIEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# é–‹å§‹å°è©± (å¯ä»¥è¼¸å…¥quit, exit, qï¼Œä¸‰é¸ä¸€åœæ­¢å°è©±)\n",
        "while True:\n",
        "  try:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "      print(\"Goodbye!\")\n",
        "      break\n",
        "    stream_graph_updates(user_input, config)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    break"
      ],
      "metadata": {
        "id": "GTx7BfHTvVVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ä½¿ç”¨è€…Açš„ç¬¬äºŒæ¬¡å°è©±\n",
        "config = {\"configurable\": {\"thread_id\": \"conversation_2\", \"user_id\": \"user_a\"}}"
      ],
      "metadata": {
        "id": "hnwxAcAqvgzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# é–‹å§‹å°è©± (å¯ä»¥è¼¸å…¥quit, exit, qï¼Œä¸‰é¸ä¸€åœæ­¢å°è©±)\n",
        "while True:\n",
        "  try:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "      print(\"Goodbye!\")\n",
        "      break\n",
        "    stream_graph_updates(user_input, config)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    break"
      ],
      "metadata": {
        "id": "qOyjZJ_HvmIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (2) é€²éšç‰ˆ\n",
        "\n",
        "ğŸ‘¨â€ğŸ“ [é€²éšç‰ˆ]\n",
        "- chatbot node: å¯ä»¥æ±ºå®šä½¿ç”¨è€…çš„å•é¡Œæ˜¯å¦éœ€è¦å¾é•·æœŸè¨˜æ†¶ä¸­å–å¾—è³‡è¨Šï¼Œä»¥åŠéœ€è¦å–å¾—ä»€éº¼è³‡è¨Š\n",
        "- write_memory node: å¯ä»¥æ•´ç†æˆç‰¹å®šæ ¼å¼ (ä¾‹å¦‚ï¼šä½¿ç”¨with_structured_outputï¼Œç›¸é—œæ¦‚å¿µå¯ä»¥å»¶ä¼¸åˆ°R3 tool callingå…§å®¹)ã€‚ä¾‹å¦‚ï¼š\n",
        "```\n",
        "user_profile = {\n",
        "  \"first_name\": \"XXXX\",\n",
        "  \"last_name\": \"OOO\",\n",
        "  \"preferred_lang\": [\"en\", \"zh-tw\"]\n",
        "}\n",
        "```\n",
        "- ä¹Ÿå¯ä»¥è‡ªè¡Œå°‡graphçµæ§‹èª¿æ•´è‡ªå·±å–œæ­¡çš„(å¢åˆªä¸åŒnode, conditional router, ...)"
      ],
      "metadata": {
        "id": "2qIEWoYKwExU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ’»code here, enjoy the ride ğŸ˜\n"
      ],
      "metadata": {
        "id": "5MLcnXZAwHeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jyJZA50xwZBf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}